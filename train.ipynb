{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3783eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3rfkiohl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2edb2bf6fd44c0d801a5cdad8ac6ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">golden-aardvark-2</strong>: <a href=\"https://wandb.ai/jli505/unet_ssl/runs/3rfkiohl\" target=\"_blank\">https://wandb.ai/jli505/unet_ssl/runs/3rfkiohl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221112_140023-3rfkiohl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3rfkiohl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c3fe074d9049c7b3cb9d4f96c04aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166698643166607, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joe/Desktop/unet/UNet-based-Denoising-Autoencoder-In-PyTorch/wandb/run-20221112_143342-2jl5defk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jli505/unet_ssl/runs/2jl5defk\" target=\"_blank\">absurd-butterfly-3</a></strong> to <a href=\"https://wandb.ai/jli505/unet_ssl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os, time, glob, time, pdb, cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg') # for servers not supporting display\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "# import neccesary libraries for defining the optimizers\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "\n",
    "from unet import UNet\n",
    "from datasets import HAR_dataset\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file) \n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"unet_ssl\", entity=\"jli505\", config=config, reinit=True)\n",
    "cfg = wandb.config\n",
    "\n",
    "test_dir = f\"{cfg.data_dir}/{cfg.val_dir}/{cfg.noisy_dir}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb8902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "\n",
      "len(train_dataset) :  82346\n",
      "len(val_dataset)   :  20587\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('device: ', device)\n",
    "\n",
    "script_time = time.time()\n",
    "\n",
    "def q(text = ''):\n",
    "    print('> {}'.format(text))\n",
    "    sys.exit()\n",
    "\n",
    "data_dir = cfg.data_dir\n",
    "train_dir = cfg.train_dir\n",
    "val_dir = cfg.val_dir\n",
    "    \n",
    "models_dir = cfg.models_dir\n",
    "if not os.path.exists(models_dir):\n",
    "    os.mkdir(models_dir)\n",
    "\n",
    "losses_dir = cfg.losses_dir\n",
    "if not os.path.exists(losses_dir):\n",
    "    os.mkdir(losses_dir)\n",
    "\n",
    "def count_parameters(model):\n",
    "    num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_parameters/1e6 # in terms of millions\n",
    "\n",
    "def plot_losses(running_train_loss, running_val_loss, train_epoch_loss, val_epoch_loss, epoch):\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    fig.suptitle('loss trends', fontsize=20)\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax4 = fig.add_subplot(224)\n",
    "\n",
    "    ax1.title.set_text('epoch train loss VS #epochs')\n",
    "    ax1.set_xlabel('#epochs')\n",
    "    ax1.set_ylabel('epoch train loss')\n",
    "    ax1.plot(train_epoch_loss)\n",
    "    \n",
    "    ax2.title.set_text('epoch val loss VS #epochs')\n",
    "    ax2.set_xlabel('#epochs')\n",
    "    ax2.set_ylabel('epoch val loss')\n",
    "    ax2.plot(val_epoch_loss)\n",
    " \n",
    "    ax3.title.set_text('batch train loss VS #batches')\n",
    "    ax3.set_xlabel('#batches')\n",
    "    ax3.set_ylabel('batch train loss')\n",
    "    ax3.plot(running_train_loss)\n",
    "\n",
    "    ax4.title.set_text('batch val loss VS #batches')\n",
    "    ax4.set_xlabel('#batches')\n",
    "    ax4.set_ylabel('batch val loss')\n",
    "    ax4.plot(running_val_loss)\n",
    "    \n",
    "    plt.savefig(os.path.join(losses_dir,'losses_{}.png'.format(str(epoch + 1).zfill(2))))\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\n",
    "\n",
    "dataset = HAR_dataset()\n",
    "sz = int(0.8*len(dataset))\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [sz, len(dataset)-sz])\n",
    "\n",
    "#train_dataset       = HAR_dataset()\n",
    "#val_dataset         = HAR_dataset()\n",
    "\n",
    "print('\\nlen(train_dataset) : ', len(train_dataset))\n",
    "print('len(val_dataset)   : ', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820b4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(train_loader): 322  @bs=256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = cfg.batch_size\n",
    "#batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "print('\\nlen(train_loader): {}  @bs={}'.format(len(train_loader), batch_size))\n",
    "\n",
    "for img, noised in train_loader:\n",
    "    display(img.shape)\n",
    "    display(noised.shape)\n",
    "    #for img, noised in\n",
    "    break\n",
    "#print('len(val_loader)  : {}  @bs={}'.format(len(val_loader), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f65dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(train_loader): 322  @bs=256\n",
      "len(val_loader)  : 81  @bs=256\n",
      "\n",
      "from scratch\n",
      "\n",
      "model has 2.682819 M parameters\n",
      "\n",
      "loss_fn        : MSELoss()\n",
      "lr             : 1e-05\n",
      "epochs_till_now: 0\n",
      "epochs from now: 12\n",
      "\n",
      "===== EPOCH 1/12 =====\n",
      "\n",
      "TRAINING...\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 025/322: 4924731.5 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 050/322: 4897873.5 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 075/322: 4865425.0 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 100/322: 4795495.0 in 0 mins 0.06 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 125/322: 4469955.5 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 150/322: 1626278.0 in 0 mins 0.06 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 175/322: 689095.75 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 200/322: 572496.125 in 0 mins 0.06 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 225/322: 526749.75 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 250/322: 520718.1875 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "train loss @batch_idx 275/322: 508597.125 in 0 mins 0.07 secs (per batch)\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n",
      "torch.Size([256, 3, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6575/3656597909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_imgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbatch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mnoisy_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = not True)\n",
    "\n",
    "print('\\nlen(train_loader): {}  @bs={}'.format(len(train_loader), batch_size))\n",
    "print('len(val_loader)  : {}  @bs={}'.format(len(val_loader), batch_size))\n",
    "\n",
    "# defining the model\n",
    "model = UNet(n_classes = 3, depth = cfg.depth, padding = True).to(device) # try decreasing the depth value if there is a memory error\n",
    "\n",
    "resume = cfg.resume\n",
    "\n",
    "if not resume:\n",
    "    print('\\nfrom scratch')\n",
    "    train_epoch_loss = []\n",
    "    val_epoch_loss = []\n",
    "    running_train_loss = []\n",
    "    running_val_loss = []\n",
    "    epochs_till_now = 0\n",
    "else:\n",
    "    ckpt_path = os.path.join(models_dir, cfg.ckpt)\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    print(f'\\nckpt loaded: {ckpt_path}')\n",
    "    model_state_dict = ckpt['model_state_dict']\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model.to(device)\n",
    "    losses = ckpt['losses']\n",
    "    running_train_loss = losses['running_train_loss']\n",
    "    running_val_loss = losses['running_val_loss']\n",
    "    train_epoch_loss = losses['train_epoch_loss']\n",
    "    val_epoch_loss = losses['val_epoch_loss']\n",
    "    epochs_till_now = ckpt['epochs_till_now']\n",
    "\n",
    "lr = cfg.lr\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "log_interval = cfg.log_interval\n",
    "epochs = cfg.epochs\n",
    "\n",
    "###\n",
    "print('\\nmodel has {} M parameters'.format(count_parameters(model)))\n",
    "print(f'\\nloss_fn        : {loss_fn}')\n",
    "print(f'lr             : {lr}')\n",
    "print(f'epochs_till_now: {epochs_till_now}')\n",
    "print(f'epochs from now: {epochs}')\n",
    "###\n",
    "\n",
    "for epoch in range(epochs_till_now, epochs_till_now+epochs):\n",
    "    print('\\n===== EPOCH {}/{} ====='.format(epoch + 1, epochs_till_now + epochs))    \n",
    "    print('\\nTRAINING...')\n",
    "    epoch_train_start_time = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, (imgs, noisy_imgs) in enumerate(train_loader):\n",
    "        batch_start_time = time.time()\n",
    "        imgs = imgs.to(device)\n",
    "        noisy_imgs = noisy_imgs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(noisy_imgs)\n",
    "        print(out.shape)\n",
    "        print(noisy_imgs.shape)\n",
    "        loss = loss_fn(out, imgs)\n",
    "        running_train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1)%log_interval == 0:\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            m,s = divmod(batch_time, 60)\n",
    "            print('train loss @batch_idx {}/{}: {} in {} mins {} secs (per batch)'.format(str(batch_idx+1).zfill(len(str(len(train_loader)))), len(train_loader), loss.item(), int(m), round(s, 2)))\n",
    "\n",
    "    mean_train_loss = np.array(running_train_loss).mean()\n",
    "    train_epoch_loss.append(mean_train_loss)\n",
    "    #wandb.log({\"epoch\":epoch})\n",
    "    wandb.log({\"train_loss\":mean_train_loss})\n",
    "\n",
    "    epoch_train_time = time.time() - epoch_train_start_time\n",
    "    m,s = divmod(epoch_train_time, 60)\n",
    "    h,m = divmod(m, 60)\n",
    "    print('\\nepoch train time: {} hrs {} mins {} secs'.format(int(h), int(m), int(s)))\n",
    "\n",
    "    print('\\nVALIDATION...')\n",
    "    epoch_val_start_time = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, noisy_imgs) in enumerate(val_loader):\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            noisy_imgs = noisy_imgs.to(device)\n",
    "\n",
    "            out = model(noisy_imgs)\n",
    "            loss = loss_fn(out, imgs)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "\n",
    "            if (batch_idx + 1)%log_interval == 0:\n",
    "                print('val loss   @batch_idx {}/{}: {}'.format(str(batch_idx+1).zfill(len(str(len(val_loader)))), len(val_loader), loss.item()))\n",
    "\n",
    "    mean_val_loss = np.array(running_val_loss).mean()\n",
    "    val_epoch_loss.append(mean_val_loss)\n",
    "    wandb.log({\"val_loss\":mean_val_loss})\n",
    "\n",
    "    epoch_val_time = time.time() - epoch_val_start_time\n",
    "    m,s = divmod(epoch_val_time, 60)\n",
    "    h,m = divmod(m, 60)\n",
    "    print('\\nepoch val   time: {} hrs {} mins {} secs'.format(int(h), int(m), int(s)))\n",
    "\n",
    "    plot_losses(running_train_loss, running_val_loss, train_epoch_loss, val_epoch_loss,  epoch)   \n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(), \n",
    "                'losses': {'running_train_loss': running_train_loss, \n",
    "                           'running_val_loss': running_val_loss, \n",
    "                           'train_epoch_loss': train_epoch_loss, \n",
    "                           'val_epoch_loss': val_epoch_loss}, \n",
    "                'epochs_till_now': epoch+1}, \n",
    "                os.path.join(models_dir, 'model{}.pth'.format(str(epoch + 1).zfill(2))))\n",
    "\n",
    "total_script_time = time.time() - script_time\n",
    "m, s = divmod(total_script_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(f'\\ntotal time taken for running this script: {int(h)} hrs {int(m)} mins {int(s)} secs')\n",
    "  \n",
    "print('\\nFin.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699effab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35816b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
